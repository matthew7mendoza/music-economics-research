{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e886db1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['SPOTIFY_CLIENT_ID', 'SPOTIFY_CLIENT_SECRET', 'REDDIT_CLIENT_ID', 'REDDIT_CLIENT_SECRET', 'LASTFM_API_KEY', 'SOUNDCHARTS_API_KEY'])\n",
      "detecting trend for Clairo\n",
      "error getting Clairo as The request failed: Google returned a response with code 429\n",
      "waiting 30 before trying again probably blocked or sum\n",
      "detecting trend for Clairo\n",
      "error getting Clairo as The request failed: Google returned a response with code 429\n",
      "waiting 60 before trying again probably blocked or sum\n",
      "detecting trend for Clairo\n",
      "error getting Clairo as The request failed: Google returned a response with code 429\n",
      "waiting 90 before trying again probably blocked or sum\n",
      "detecting trend for Clairo\n",
      "error getting Clairo as The request failed: Google returned a response with code 429\n",
      "waiting 120 before trying again probably blocked or sum\n",
      "detecting trend for Clairo\n",
      " spike detected for Clairo on 2025-04-13\n",
      " determine_controversy Clairo spike on 2025-04-13 artist scores: score =nan mean_sent=0.000 keywords=0 artist examples: neg_examples = 0 n_posts =0 n_comments =0 => HYPE\n",
      "Clairo classified as hype\n",
      "Error getting artist ID for Clairo: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 10s...\n",
      "Error getting artist ID for Clairo: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 20s...\n",
      "Error getting artist ID for Clairo: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 30s...\n",
      "Error getting artist ID for Clairo: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 40s...\n",
      "Error getting artist ID for Clairo: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 50s...\n",
      "Failed to get artist ID for Clairo after 5 attempts.\n",
      "no listener data found for Clairo\n",
      "detecting trend for Mac Miller\n",
      "error getting Mac Miller as The request failed: Google returned a response with code 429\n",
      "waiting 30 before trying again probably blocked or sum\n",
      "detecting trend for Mac Miller\n",
      "error getting Mac Miller as The request failed: Google returned a response with code 429\n",
      "waiting 60 before trying again probably blocked or sum\n",
      "detecting trend for Mac Miller\n",
      " spike detected for Mac Miller on 2025-01-12\n",
      " determine_controversy Mac Miller spike on 2025-01-12 artist scores: score =nan mean_sent=0.000 keywords=0 artist examples: neg_examples = 0 n_posts =0 n_comments =0 => HYPE\n",
      "Mac Miller classified as hype\n",
      "Error getting artist ID for Mac Miller: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 10s...\n",
      "Error getting artist ID for Mac Miller: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 20s...\n",
      "Error getting artist ID for Mac Miller: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 30s...\n",
      "Error getting artist ID for Mac Miller: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 40s...\n",
      "Error getting artist ID for Mac Miller: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 50s...\n",
      "Failed to get artist ID for Mac Miller after 5 attempts.\n",
      "no listener data found for Mac Miller\n",
      "detecting trend for Maroon 5\n",
      "error getting Maroon 5 as The request failed: Google returned a response with code 429\n",
      "waiting 30 before trying again probably blocked or sum\n",
      "detecting trend for Maroon 5\n",
      "error getting Maroon 5 as The request failed: Google returned a response with code 429\n",
      "waiting 60 before trying again probably blocked or sum\n",
      "detecting trend for Maroon 5\n",
      " spike detected for Maroon 5 on 2025-01-26\n",
      " determine_controversy Maroon 5 spike on 2025-01-26 artist scores: score =nan mean_sent=0.000 keywords=0 artist examples: neg_examples = 0 n_posts =0 n_comments =0 => HYPE\n",
      "Maroon 5 classified as hype\n",
      "Error getting artist ID for Maroon 5: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 10s...\n",
      "Error getting artist ID for Maroon 5: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 20s...\n",
      "Error getting artist ID for Maroon 5: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 30s...\n",
      "Error getting artist ID for Maroon 5: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 40s...\n",
      "Error getting artist ID for Maroon 5: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 50s...\n",
      "Failed to get artist ID for Maroon 5 after 5 attempts.\n",
      "no listener data found for Maroon 5\n",
      "detecting trend for PinkPantheress\n",
      "error getting PinkPantheress as The request failed: Google returned a response with code 429\n",
      "waiting 30 before trying again probably blocked or sum\n",
      "detecting trend for PinkPantheress\n",
      " spike detected for PinkPantheress on 2025-07-13\n",
      " determine_controversy PinkPantheress spike on 2025-07-13 artist scores: score =0.5 mean_sent=0.146 keywords=1 artist examples: neg_examples = 1 n_posts =4 n_comments =10 => CONTROVERSY\n",
      "Error getting artist ID for PinkPantheress: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 10s...\n",
      "Error getting artist ID for PinkPantheress: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 20s...\n",
      "Error getting artist ID for PinkPantheress: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 30s...\n",
      "Error getting artist ID for PinkPantheress: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 40s...\n",
      "Error getting artist ID for PinkPantheress: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 50s...\n",
      "Failed to get artist ID for PinkPantheress after 5 attempts.\n",
      "no listener data found for PinkPantheress\n",
      "detecting trend for Britney Spears\n",
      " spike detected for Britney Spears on 2025-10-12\n",
      " determine_controversy Britney Spears spike on 2025-10-12 artist scores: score =0.643 mean_sent=0.266 keywords=0 artist examples: neg_examples = 0 n_posts =4 n_comments =3 => CONTROVERSY\n",
      "Error getting artist ID for Britney Spears: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 10s...\n",
      "Error getting artist ID for Britney Spears: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 20s...\n",
      "Error getting artist ID for Britney Spears: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 30s...\n",
      "Error getting artist ID for Britney Spears: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 40s...\n",
      "Error getting artist ID for Britney Spears: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 50s...\n",
      "Failed to get artist ID for Britney Spears after 5 attempts.\n",
      "no listener data found for Britney Spears\n",
      "detecting trend for The Smiths\n",
      " spike detected for The Smiths on 2025-06-22\n",
      " determine_controversy The Smiths spike on 2025-06-22 artist scores: score =0.139 mean_sent=0.081 keywords=0 artist examples: neg_examples = 0 n_posts =4 n_comments =2 => HYPE\n",
      "The Smiths classified as hype\n",
      "Error getting artist ID for The Smiths: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 10s...\n",
      "Error getting artist ID for The Smiths: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 20s...\n",
      "Error getting artist ID for The Smiths: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 30s...\n",
      "Error getting artist ID for The Smiths: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 40s...\n",
      "Error getting artist ID for The Smiths: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 50s...\n",
      "Failed to get artist ID for The Smiths after 5 attempts.\n",
      "no listener data found for The Smiths\n",
      "detecting trend for d4vid\n",
      " spike detected for d4vid on 2025-09-14\n",
      " determine_controversy d4vid spike on 2025-09-14 artist scores: score =0.0 mean_sent=0.000 keywords=0 artist examples: neg_examples = 0 n_posts =1 n_comments =0 => HYPE\n",
      "d4vid classified as hype\n",
      "Error getting artist ID for d4vid: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 10s...\n",
      "Error getting artist ID for d4vid: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 20s...\n",
      "Error getting artist ID for d4vid: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 30s...\n",
      "Error getting artist ID for d4vid: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 40s...\n",
      "Error getting artist ID for d4vid: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 50s...\n",
      "Failed to get artist ID for d4vid after 5 attempts.\n",
      "no listener data found for d4vid\n",
      "detecting trend for Kesha\n",
      " spike detected for Kesha on 2025-07-06\n",
      " determine_controversy Kesha spike on 2025-07-06 artist scores: score =0.504 mean_sent=0.122 keywords=0 artist examples: neg_examples = 0 n_posts =4 n_comments =6 => CONTROVERSY\n",
      "Error getting artist ID for Kesha: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 10s...\n",
      "Error getting artist ID for Kesha: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 20s...\n",
      "Error getting artist ID for Kesha: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 30s...\n",
      "Error getting artist ID for Kesha: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 40s...\n",
      "Error getting artist ID for Kesha: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 50s...\n",
      "Failed to get artist ID for Kesha after 5 attempts.\n",
      "no listener data found for Kesha\n",
      "detecting trend for System of a Down\n",
      "error getting System of a Down as The request failed: Google returned a response with code 429\n",
      "waiting 30 before trying again probably blocked or sum\n",
      "detecting trend for System of a Down\n",
      " spike detected for System of a Down on 2024-12-15\n",
      " determine_controversy System of a Down spike on 2024-12-15 artist scores: score =0.301 mean_sent=0.108 keywords=0 artist examples: neg_examples = 0 n_posts =5 n_comments =10 => CONTROVERSY\n",
      "Error getting artist ID for System of a Down: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 10s...\n",
      "Error getting artist ID for System of a Down: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 20s...\n",
      "Error getting artist ID for System of a Down: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 30s...\n",
      "Error getting artist ID for System of a Down: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 40s...\n",
      "Error getting artist ID for System of a Down: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 50s...\n",
      "Failed to get artist ID for System of a Down after 5 attempts.\n",
      "no listener data found for System of a Down\n",
      "detecting trend for SZA\n",
      " spike detected for SZA on 2025-02-09\n",
      " determine_controversy SZA spike on 2025-02-09 artist scores: score =0.524 mean_sent=0.196 keywords=0 artist examples: neg_examples = 0 n_posts =8 n_comments =20 => CONTROVERSY\n",
      "Error getting artist ID for SZA: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 10s...\n",
      "Error getting artist ID for SZA: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 20s...\n",
      "Error getting artist ID for SZA: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 30s...\n",
      "Error getting artist ID for SZA: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 40s...\n",
      "Error getting artist ID for SZA: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Retrying in 50s...\n",
      "Failed to get artist ID for SZA after 5 attempts.\n",
      "no listener data found for SZA\n",
      "no new data from this. nothing to save or export.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Version 3 (NO paid API Yet) (Lol waiting for club funding!)\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import praw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "import pytrends\n",
    "from pytrends.request import TrendReq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from scipy.stats import ttest_ind\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import logging\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from google.oauth2.service_account import Credentials\n",
    "import random\n",
    "pytrends = TrendReq(hl=\"en-US\", tz=360)\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "google_credentials = os.getenv(\"GOOGLE_CREDENTIALS_PATH\")\n",
    "spotify_client_id = os.getenv(\"SPOTIFY_CLIENT_ID\")\n",
    "spotify_client_secret = os.getenv(\"SPOTIFY_CLIENT_SECRET\")\n",
    "reddit_client_id = os.getenv(\"REDDIT_CLIENT_ID\")\n",
    "reddit_client_secret = os.getenv(\"REDDIT_CLIENT_SECRET\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename = \"run_log.txt\",\n",
    "    level = logging.INFO,\n",
    "    format = \"%(asctime)s - %(levelname)s - %(message)s\" \n",
    ")\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "\n",
    "def fetch_reddit_posts(subreddit_name, limit = 100, sort = \"hot\", reddit = None):\n",
    "\n",
    "    print(f\"searchying through r/{subreddit_name}\")\n",
    "    posts_data =[]\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "    sort_map = {\n",
    "        \"hot\": subreddit.hot,\n",
    "        \"new\": subreddit.new,\n",
    "        \"top\": subreddit.top,\n",
    "        \"rising\": subreddit.rising\n",
    "    }\n",
    "\n",
    "    submissions = sort_map.get(sort, subreddit.hot)(limit = limit)\n",
    "\n",
    "    for submission in submissions:\n",
    "        try:\n",
    "            posts_data.append({\n",
    "                \"post_id\": submission.id,\n",
    "                \"title\": submission.title,\n",
    "                \"score\": submission.score,\n",
    "                \"num_comments\": submission.num_comments,\n",
    "                \"created_utc\": submission.created_utc,\n",
    "                \"upvote_ratio\": submission.upvote_ratio,\n",
    "                \"selftext\": submission.selftext,\n",
    "                \"url\": submission.url\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"error w/ {submission.id}: {e}\")\n",
    "            time.sleep(2)\n",
    "        \n",
    "    df = pd.DataFrame(posts_data)\n",
    "    print(f\"collected{len(df)} posts\")\n",
    "    return df\n",
    "    \n",
    "def get_comment_for_post(post_id, reddit, max_comments = 50):\n",
    "    comments_texts = []\n",
    "    try:\n",
    "        submission = reddit.submission(id = post_id)\n",
    "        submission.comments.replace_more(limit = 0)\n",
    "\n",
    "        for comment in submission.comments[:max_comments]:\n",
    "            if not comment.body or comment.body in [\"[deleted]\", \"[removed]\"]:\n",
    "                continue\n",
    "            if len(comment.body.split()) < 3:\n",
    "                continue\n",
    "            comments_texts.append(comment.body)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"error getting comments for {post_id} {e}\")\n",
    "        time.sleep(3)\n",
    "\n",
    "    return comments_texts\n",
    "        \n",
    "def analyze_sentiment(text):\n",
    "\n",
    "    try:\n",
    "        blob = TextBlob(text)\n",
    "        return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
    "    except Exception as e:\n",
    "        print(\"sentiment error probabbly will never get this error though\")\n",
    "        return np.nan, np.nan\n",
    "\n",
    "def compute_controversy_score(upvote_ratio, num_comments):\n",
    "    try:\n",
    "        return (1 - upvote_ratio) * np.log1p(num_comments)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def compile_data(reddit, subreddit_name, post_limit = 100, max_comments = 50): \n",
    "\n",
    "    posts_df = fetch_reddit_posts(subreddit_name, limit = post_limit, reddit = reddit)\n",
    "\n",
    "    all_comments = []\n",
    "    print(\"\\ngetting comments and analyzing sentiment\")\n",
    "    for i, row in posts_df.iterrows():\n",
    "        comments = get_comment_for_post(row[\"post_id\"], reddit, max_comments = max_comments)\n",
    "        joined_comments = \" \".join(comments)\n",
    "        polarity, subjectivity = analyze_sentiment(joined_comments)\n",
    "        controversy = compute_controversy_score(row[\"upvote_ratio\"], row[\"num_comments\"])\n",
    "\n",
    "        all_comments.append({\n",
    "            \"post_id\": row[\"post_id\"], \n",
    "            \"comments_text\": joined_comments,\n",
    "            \"sentiment_polarity\": polarity,\n",
    "            \"sentiment_subjectivity\": subjectivity,\n",
    "            \"controversy_score\": controversy\n",
    "        })\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"all posts processed\")\n",
    "        \n",
    "        time.sleep(1.5)\n",
    "    \n",
    "    comments_df = pd.DataFrame(all_comments)\n",
    "    final_df = pd.merge(posts_df, comments_df, on = \"post_id\", how = \"left\")\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def log_metadata(artist_name, n_posts, n_comments, duration):\n",
    "    meta_path = \"sampling.log.csv\" \n",
    "    new_entry = pd.DataFrame([{\n",
    "        \"artist\": artist_name,\n",
    "        \"n_posts\": n_posts,\n",
    "        \"n_comments\": n_comments,\n",
    "        \"duration_sec\": duration,\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }])\n",
    "\n",
    "    if os.path.exists(meta_path):\n",
    "        existing = pd.read_csv(meta_path)\n",
    "        df = pd.concat([existing, new_entry], ignore_index = True)\n",
    "    else:\n",
    "        df = new_entry\n",
    "    df.to_csv(meta_path, index = False)\n",
    "\n",
    "def bootstrap_ci(data, n_resamples = 10000, ci = 95):\n",
    "    if len(data) < 2:\n",
    "        return (np.nan, np.nan)\n",
    "    resamples = np.random.choice(data, (n_resamples, len(data)), replace = True)\n",
    "    means = resamples.mean(axis = 1)\n",
    "    lower = np.percentile(means, (100 - ci) / 2) \n",
    "    upper = np.percentile(means, 100 - (100 - ci) / 2)\n",
    "    return (lower, upper)\n",
    "\n",
    "\n",
    "\n",
    "KEYWORDS = [\n",
    "    \"drama\", \"cancelled\", \"racist\", \"assault\", \"lawsuit\", \"controversy\", \"apology\",\n",
    "    \"accused\", \"kill\", \"murder\", \"over\", \"cooked\", \"horrible\", \"trash\",\n",
    "    \"criticism\", \"disrespect\", \"problematic\", \"backlash\", \"allegation\", \"scandal\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "with open(\"config.json\") as f:\n",
    "    keys = json.load(f)\n",
    "\n",
    "spotify = spotipy.Spotify(\n",
    "    auth_manager = SpotifyClientCredentials(\n",
    "        client_id = keys[\"SPOTIFY_CLIENT_ID\"],\n",
    "        client_secret = keys[\"SPOTIFY_CLIENT_SECRET\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id = keys[\"REDDIT_CLIENT_ID\"],\n",
    "    client_secret = keys[\"REDDIT_CLIENT_SECRET\"],\n",
    "    user_agent = \"music_sentiment_bot by u/Many-Lingonberry1688\"\n",
    ")\n",
    "\n",
    "print(keys.keys())\n",
    "\n",
    "SOUNDCHARTS_KEY = keys[\"SOUNDCHARTS_API_KEY\"]\n",
    "BASE_URL = \"https://api.soundcharts.com/api/v2\" \n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {SOUNDCHARTS_KEY}\"\n",
    "}\n",
    "\n",
    "\n",
    "#ai this bs cus the api was being annoying \n",
    "def get_artist_id(artist_name, max_retries=5):\n",
    "    url = f\"{BASE_URL}/artist/search\"\n",
    "    parameters = {\"q\": artist_name}\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, params=parameters, timeout=10)\n",
    "            if response.status_code == 429:\n",
    "                wait_time = 60 * (attempt + 1)\n",
    "                print(f\"Rate limited when fetching ID for {artist_name}, waiting {wait_time}s...\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "            response.raise_for_status()\n",
    "\n",
    "            data = response.json()\n",
    "            if \"items\" not in data or len(data[\"items\"]) == 0:\n",
    "                print(f\"{artist_name} not found in Soundcharts.\")\n",
    "                return None\n",
    "\n",
    "            return data[\"items\"][0][\"id\"]\n",
    "\n",
    "        except Exception as e:\n",
    "            wait_time = 10 * (attempt + 1)\n",
    "            print(f\"Error getting artist ID for {artist_name}: {e}. Retrying in {wait_time}s...\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "    print(f\"Failed to get artist ID for {artist_name} after {max_retries} attempts.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def historical_listener_data(artist_name, start_date, end_date, max_retries=5):\n",
    "    artist_id = get_artist_id(artist_name)\n",
    "    if not artist_id:\n",
    "        return None\n",
    "\n",
    "    url = f\"{BASE_URL}/artist/{artist_id}/audience/streaming\"\n",
    "    parameters = {\"startDate\": start_date, \"endDate\": end_date}\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, params=parameters, timeout=10)\n",
    "            if response.status_code == 429:\n",
    "                wait_time = 60 * (attempt + 1)\n",
    "                print(f\"Rate limited fetching data for {artist_name}, waiting {wait_time}s...\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "            response.raise_for_status()\n",
    "\n",
    "            data = response.json()\n",
    "            if \"data\" not in data or len(data[\"data\"]) == 0:\n",
    "                print(f\"No audience data for {artist_name}.\")\n",
    "                return None\n",
    "\n",
    "            df = pd.DataFrame(data[\"data\"])\n",
    "            df[\"artist\"] = artist_name\n",
    "            df[\"retrieved_at\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            return df\n",
    "\n",
    "        except Exception as e:\n",
    "            wait_time = 10 * (attempt + 1)\n",
    "            print(f\"Error fetching data for {artist_name}: {e}. Retrying in {wait_time}s...\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "    print(f\"Failed to retrieve data for {artist_name} after {max_retries} attempts.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "                                                     \n",
    "def get_artist_sentiment(artist_name, number_of_posts = 50, time_filter = \"week\"):\n",
    "    start_time = time.time()\n",
    "    sentiments = []\n",
    "    examples = {\"positive\": [], \"negative\": []}\n",
    "    processed_ids = set()\n",
    "    seen_comments = set()\n",
    "    n_posts = 0\n",
    "    n_comments = 0\n",
    "\n",
    "    subreddits = [\n",
    "        \"music\", \"popheads\", \"hiphopheads\", \"indieheads\",\n",
    "        \"popculturechat\", \"GenZ\", \"morbidquestions\", \"askreddit\",\n",
    "        \"hiphopcirclejerk\", \"blackpeopletwitter\", \"letstalkmusic\"\n",
    "    ]\n",
    "    np.random.shuffle(subreddits)\n",
    "\n",
    "    keywords = [\n",
    "        \"song\", \"album\", \"music\", \"track\", \"listen\", \"release\",\n",
    "        \"concert\", \"lyrics\", \"vocals\", \"fanbase\", \"chart\", \"award\",\n",
    "        \"cancel\", \"controversy\", \"drama\", \"problematic\", \"backlash\",\n",
    "        \"scandal\", \"beef\", \"apology\", \"offend\", \"allegation\", \"lawsuit\",\n",
    "        \"accused\", \"critic\", \"criticize\"\n",
    "    ]\n",
    "\n",
    "    def is_relevant(text):\n",
    "        if not text:\n",
    "            return False\n",
    "        lower = text.lower()\n",
    "        return artist_name.lower() in lower or any(k in lower for k in keywords)\n",
    "    \n",
    "    try:\n",
    "        for sub in subreddits:\n",
    "            if n_posts >= number_of_posts:\n",
    "                break\n",
    "\n",
    "            for submission in reddit.subreddit(sub).search(\n",
    "                artist_name, limit = 5, sort = \"new\", time_filter = time_filter \n",
    "            ):\n",
    "                if submission.id in processed_ids:\n",
    "                    continue\n",
    "                processed_ids.add(submission.id)\n",
    "\n",
    "                title_text = (submission.title or \"\") + \" \" + (getattr(submission, \"selftext\", \"\") or \"\")\n",
    "                if not is_relevant(title_text):\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    polarity = TextBlob(title_text).sentiment.polarity\n",
    "                except Exception:\n",
    "                    polarity = 0.0\n",
    "                sentiments.append(polarity)\n",
    "                n_posts += 1\n",
    "\n",
    "                if polarity > 0.3 and len(examples[\"positive\"]) < 2:\n",
    "                    examples[\"positive\"].append(submission.title)\n",
    "                elif polarity < -0.3 and len(examples[\"negative\"]) < 2:\n",
    "                    examples[\"negative\"].append(submission.title)\n",
    "                \n",
    "                submission.comments.replace_more(limit = 0)\n",
    "                comment_count = 0\n",
    "\n",
    "                for comment in submission.comments:\n",
    "                    if comment_count >= 3:\n",
    "                        break\n",
    "                    body = getattr(comment, \"body\", \"\")\n",
    "                    if not body or len(body.strip()) < 20 or body in seen_comments:\n",
    "                        continue\n",
    "                    if not is_relevant(body):\n",
    "                        continue\n",
    "                    seen_comments.add(body)\n",
    "                    \n",
    "                    try:\n",
    "                        cpol = TextBlob(body).sentiment.polarity\n",
    "                    except Exception:\n",
    "                        cpol = 0.0\n",
    "                    sentiments.append(cpol)\n",
    "                    n_comments += 1\n",
    "                    if cpol > 0.3 and len(examples[\"positive\"]) < 4:\n",
    "                        examples [\"positive\"].append(body[:200])\n",
    "                    elif cpol <-0.3 and len(examples[\"negative\"]) < 4:\n",
    "                        examples[\"negative\"].append(body[:200])\n",
    "                    comment_count += 1\n",
    "                    time.sleep(random.uniform(0.5, 1.5))\n",
    "                time.sleep(0.1)\n",
    "    except Exception as e:\n",
    "        print(f\"reddit api error: {e}\")\n",
    "        return np.nan, examples\n",
    "    \n",
    "    duration = round(time.time() - start_time, 2)\n",
    "    log_metadata(artist_name, n_posts, n_comments, duration)\n",
    "\n",
    "    if not sentiments:\n",
    "        return np.nan, examples\n",
    "    \n",
    "    std_sentiment = float(np.std(sentiments))\n",
    "    mean_sentiment = float(np.mean(sentiments))\n",
    "    controversy_score = min(std_sentiment * 2, 1.0)\n",
    "\n",
    "    examples[\"n_posts\"] = n_posts\n",
    "    examples[\"n_comments\"] = n_comments\n",
    "    examples[\"mean_sentiment\"] =mean_sentiment\n",
    "\n",
    "    return round(controversy_score, 3), examples \n",
    "\n",
    "\n",
    "def trend_detector(artist_name, timeframe = \"today 12-m\"):\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            print(f\"detecting trend for {artist_name}\")\n",
    "            pytrends.build_payload([artist_name], cat = 0, timeframe = timeframe, geo =\"\", gprop =\"\")\n",
    "            df = pytrends.interest_over_time()\n",
    "\n",
    "            if df.empty:\n",
    "                print(f\"nothing found for {artist_name}, skipping\")\n",
    "                return None\n",
    "\n",
    "            max_interest = df[artist_name].max()\n",
    "            spike_date = df[df[artist_name] == max_interest].index[-1]\n",
    "            print(f\" spike detected for {artist_name} on {spike_date.strftime('%Y-%m-%d')}\")\n",
    "            time.sleep(random.uniform(15, 45))\n",
    "            return spike_date.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"error getting {artist_name} as {e}\")\n",
    "            wait_time = 30 * (attempt + 1)\n",
    "            print(f\"waiting {wait_time} before trying again probably blocked or sum\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "    print(f\"failed to get data for {artist_name} even after multiple attempts\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def determine_controversy(artist_name, spike_date):\n",
    "    try:\n",
    "        start = (datetime.strptime(spike_date, \"%Y-%m-%d\") - timedelta(days= 3)).strftime(\"%Y-%m-%d\")\n",
    "        end = (datetime.strptime(spike_date, \"%Y-%m-%d\") + timedelta(days= 3)).strftime(\"%Y-%m-%d\")\n",
    "    except Exception:\n",
    "        start = end = spike_date\n",
    "    \n",
    "    score, examples = get_artist_sentiment(artist_name, time_filter = \"week\")\n",
    "    if isinstance(examples, dict):\n",
    "        mean_sent = examples.get(\"mean_sentiment\", 0.0)\n",
    "        n_posts = examples.get(\"n_posts\", 0)\n",
    "        n_comments = examples.get(\"n_comments\", 0)\n",
    "    else:\n",
    "        mean_sent = 0.0\n",
    "        n_posts = 0\n",
    "        n_comments = 0\n",
    "    \n",
    "    joined_text = \"\"\n",
    "    if isinstance(examples, dict):\n",
    "        joined_text = \" \".join(examples.get(\"negative\", []) + examples.get(\"positive\", []))\n",
    "    joined_lower = joined_text.lower()\n",
    "\n",
    "    keyword_count = 0\n",
    "    for k in KEYWORDS:\n",
    "        if k in joined_lower:\n",
    "            keyword_count += 1\n",
    "\n",
    "    if isinstance(examples, dict):\n",
    "        negative_list = examples.get(\"negative\", [])\n",
    "        n_negative_examples = len(negative_list)\n",
    "    else:\n",
    "        n_negative_examples = 0 \n",
    "\n",
    "    SCORE_THRESH = 0.25\n",
    "    KEYWORD_COUNT_THRESH = 2\n",
    "    MEAN_SENT_THRESH = -0.12\n",
    "    NEG_EXAMPLES_THRESH = 2\n",
    "\n",
    "    is_strong_score = (isinstance(score, (int, float)) and score >= SCORE_THRESH)\n",
    "    is_keyword_heavy = (keyword_count >= KEYWORD_COUNT_THRESH)\n",
    "    is_mean_negative = (isinstance(mean_sent, (int, float)) and mean_sent <= MEAN_SENT_THRESH)\n",
    "    has_negative_examples = (n_negative_examples >= NEG_EXAMPLES_THRESH)\n",
    "\n",
    "    if is_strong_score:\n",
    "        label = \"controversy\"\n",
    "    elif is_keyword_heavy:\n",
    "        label = \"controversy\" \n",
    "    elif is_mean_negative and (has_negative_examples or keyword_count >= 1):\n",
    "        label = \"controversy\"\n",
    "    elif has_negative_examples and (score >= (SCORE_THRESH * 0.6)):\n",
    "        label = \"controversy\"\n",
    "    else:\n",
    "        label = \"hype\"\n",
    "    \n",
    "    print(\n",
    "        f\" determine_controversy {artist_name} spike on {spike_date} \"\n",
    "        f\"artist scores: score ={score} mean_sent={mean_sent:.3f} keywords={keyword_count} \"\n",
    "        f\"artist examples: neg_examples = {n_negative_examples} n_posts ={n_posts} n_comments ={n_comments} => {label.upper()}\"\n",
    "    )\n",
    "\n",
    "    logging.info(f\"determine_controversy: {artist_name} {spike_date} label={label} score={score} \"\n",
    "                 f\"mean_sent={mean_sent:.3f} keywords={keyword_count} neg_ex={n_negative_examples}\")\n",
    "    \n",
    "    return label\n",
    "    \n",
    "\n",
    "\n",
    "def statistical_summary(csv_path = \"artist_controversy_data.csv\"):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df[\"difference_norm\"] = df[\"difference\"] / df[\"before_listeners\"]\n",
    "\n",
    "    print(\"\\n normalized listening change by label:\")\n",
    "    print(df.groupby(\"label\")[\"difference_norm\"].describe(percentiles = [0.25, .5, .75]))\n",
    "\n",
    "    hype = df[df[\"label\"] == \"hype\"][\"difference_norm\"].dropna()\n",
    "    controversy = df[df[\"label\"] == \"controversy\"][\"difference_norm\"].dropna()\n",
    "\n",
    "    if len(hype) > 2 and len(controversy) > 2:\n",
    "        t, p = ttest_ind(hype, controversy, equal_var = False)\n",
    "        ci_hype = bootstrap_ci(hype)\n",
    "        ci_cont = bootstrap_ci(controversy)\n",
    "        print(f\"t-test: T = {t:.3f}, p = {p:.5f}\")\n",
    "        print(f\"Hype average plus or minus CI: {hype.mean():.3f} ({ci_hype[0]:.3f}, {ci_hype[1]:.3f})\")\n",
    "        print(f\"Controversy average plus or minus CI: {controversy.mean():.3f} ({ci_cont[0]:.3f}, {ci_cont[1]:.3f})\")\n",
    "    else:\n",
    "        print(\"lacking data\")\n",
    "\n",
    "def get_top_artists_lastfm(api_key, limit=100):\n",
    "    url = \"http://ws.audioscrobbler.com/2.0/\"\n",
    "    parameters = {\n",
    "        \"method\": \"chart.gettopartists\",\n",
    "        \"api_key\": api_key,\n",
    "        \"format\": \"json\",\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    response = requests.get(url, params = parameters)\n",
    "    data = response.json()\n",
    "\n",
    "    if \"artists\" not in data or \"artist\" not in data[\"artists\"]:\n",
    "        print(\"couldn't fetch top artists\")\n",
    "        return []\n",
    "\n",
    "    artist_names = [a[\"name\"] for a in data[\"artists\"][\"artist\"]]\n",
    "    np.random.shuffle(artist_names)  \n",
    "    return artist_names\n",
    "\n",
    "def antidupe_and_merge(new_df, save_path):\n",
    "    if os.path.exists(save_path):\n",
    "        existing = pd.read_csv(save_path)\n",
    "        combined = pd.concat([existing, new_df], ignore_index = True)\n",
    "        combined.drop_duplicates(subset=[\"artist\", \"spike_date\"], keep = \"last\", inplace = True)\n",
    "    else:\n",
    "        combined = new_df\n",
    "    \n",
    "    combined.to_csv(save_path, index = False)\n",
    "\n",
    "    print(f\"information saved and removed duplicates to {save_path}\")\n",
    "    return combined\n",
    "\n",
    "def export_to_google_sheets(df, sheet_name = \"Music Economics Data\"):\n",
    "    json_path = google_credentials\n",
    "    creds = Credentials.from_service_account_file(json_path)\n",
    "    client = gspread.authorize(creds)\n",
    "    sheet = client.open(sheet_name).sheet1\n",
    "\n",
    "    existing_records = len(sheet.get_all_values())\n",
    "    if existing_records > 0:\n",
    "        start_row = existing_records + 1\n",
    "    else:\n",
    "        start_row = 1\n",
    "    \n",
    "    set_with_dataframe(sheet, df, row = start_row, include_column_header = (existing_records == 0))\n",
    "    print(\"changes applied to google sheets\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    save_path = \"artist_controversy_data.csv\" \n",
    "    api_key = keys[\"LASTFM_API_KEY\"]\n",
    "\n",
    "    if os.path.exists(save_path):\n",
    "        existing_df = pd.read_csv(save_path)\n",
    "        existing_artists = set(existing_df[\"artist\"])\n",
    "    else:\n",
    "        existing_df = pd.DataFrame()\n",
    "        existing_artists = set()\n",
    "\n",
    "    all_artists = get_top_artists_lastfm(api_key, limit = 100)\n",
    "    new_artists = [\"Kendrick Lamar\", \"d4vid\", \"Drake\"]\n",
    "    for i in all_artists:\n",
    "        if not i in existing_artists:\n",
    "            new_artists.append(i)\n",
    "    \n",
    "    random.shuffle(new_artists)\n",
    "    artists = new_artists[:10]\n",
    "    \n",
    "    all_results = []\n",
    "\n",
    "    for artist in artists:\n",
    "\n",
    "        spike_date = trend_detector(artist)\n",
    "        if not spike_date:\n",
    "            print(f\"no trend found for {artist}, skipping\")\n",
    "            continue\n",
    "\n",
    "        label = determine_controversy(artist, spike_date)\n",
    "        if label == \"hype\":\n",
    "            print(f\"{artist} classified as hype\")\n",
    "        \n",
    "        start_date = (datetime.strptime(spike_date, \"%Y-%m-%d\") - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "        end_date = (datetime.strptime(spike_date, \"%Y-%m-%d\") + timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "        listener_df = historical_listener_data(artist, start_date, end_date)\n",
    "\n",
    "        if listener_df is None or listener_df.empty:\n",
    "            print(f\"no listener data found for {artist}\")\n",
    "            continue\n",
    "\n",
    "        before_score, _ = get_artist_sentiment(artist, time_filter = \"month\")\n",
    "        after_score, _ = get_artist_sentiment(artist, time_filter = \"week\")\n",
    "\n",
    "        date_col = \"date\" if \"date\" in listener_df.columns else \"day\"\n",
    "        before_mean = listener_df[listener_df[date_col] < spike_date][\"value\"].mean()\n",
    "        after_mean = listener_df[listener_df[date_col] > spike_date][\"value\"].mean()\n",
    "\n",
    "\n",
    "        if pd.isna(before_mean) or pd.isna(after_mean):\n",
    "            print(f\"incomplete listening data for {artist}, skipping\")\n",
    "            continue\n",
    "\n",
    "        result = {\n",
    "            \"artist\": artist,\n",
    "            \"spike_date\": spike_date,\n",
    "            \"label\": label,\n",
    "            \"before_listeners\": before_mean,\n",
    "            \"after_listeners\": after_mean,\n",
    "            \"before_score\": before_score,\n",
    "            \"after_score\": after_score,\n",
    "            \"difference\": after_mean - before_mean,\n",
    "            \"percent_change\": ((after_mean - before_mean) / before_mean) * 100,\n",
    "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "\n",
    "        all_results.append(result)\n",
    "        time.sleep(3)\n",
    "    \n",
    "    if not all_results:\n",
    "        print(\"no new data from this. nothing to save or export.\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "\n",
    "    df = pd.DataFrame(all_results)\n",
    "    merged = antidupe_and_merge(df, save_path)\n",
    "    statistical_summary(save_path)\n",
    "    export_to_google_sheets(merged)\n",
    "\n",
    "    print(f\"saved and exportedr {len(df)}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "                                                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef6ceef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
